{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_docs as tfdocs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = numpy.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
    "    datasets=datass.values\n",
    "    train_size = int(len(datasets) * data_partition)\n",
    "    test_size = len(datasets) - train_size\n",
    "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    X_train=pd.DataFrame(trainX)\n",
    "    Y_train=pd.DataFrame(trainY)\n",
    "    X_test=pd.DataFrame(testX)\n",
    "    Y_test=pd.DataFrame(testY) \n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    \n",
    "    X= sc_X.fit_transform(X_train)\n",
    "    y= sc_y.fit_transform(Y_train)\n",
    "    X1= sc_X.fit_transform(X_test)\n",
    "    y1= sc_y.fit_transform(Y_test)\n",
    "    y=y.ravel()\n",
    "    y1=y1.ravel()  \n",
    "    trainX1 = numpy.reshape(X, (X.shape[0],1,X.shape[1]))\n",
    "    testX1 = numpy.reshape(X1, (X1.shape[0],1,X1.shape[1]))\n",
    "      \n",
    "    numpy.random.seed(1234)\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(1234)\n",
    "    \n",
    "    import os \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation\n",
    "    from keras.layers.recurrent import LSTM\n",
    "\n",
    "\n",
    "    neuron=neuron\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = neuron,input_shape=(trainX1.shape[1], trainX1.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss='mse',optimizer=optimizer)\n",
    "#    model.summary()\n",
    "    \n",
    "\n",
    "  # Fitting the RNN to the Training s\n",
    "    model.fit(trainX1, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
    "  # make predictions\n",
    "    y_pred_train = model.predict(trainX1)\n",
    "    y_pred_test = model.predict(testX1)\n",
    "    y_pred_test= numpy.array(y_pred_test).ravel()\n",
    "\n",
    "    y_pred_test=pd.DataFrame(y_pred_test)\n",
    "    y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
    "    y1=pd.DataFrame(y1)\n",
    "      \n",
    "    y_test= sc_y.inverse_transform (y1)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    mape=mean_absolute_percentage_error(y_test,y_pred_test1)\n",
    "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1))\n",
    "    mae=metrics.mean_absolute_error(y_test,y_pred_test1)\n",
    "    return mape,rmse,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
